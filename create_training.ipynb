{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "from sklearn.preprocessing import MinMaxScaler, OneHotEncoder, OrdinalEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "import subprocess\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First threshold: 87317.97175088 and Second threshold: 142840.60089824\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"/Users/advaitbalaji/se_exercise/AnalysisData.csv\", header=0)\n",
    "vals = df[\"CumOil12Month\"].to_numpy()\n",
    "first_thresh = np.percentile(vals, 33.33)\n",
    "second_thresh = np.percentile(vals, 66.66)\n",
    "print(f\"First threshold: {first_thresh} and Second threshold: {second_thresh}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({2: 1700, 1: 1699, 0: 1699})"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "category = [0, 1, 2]\n",
    "CumOilCategory = []\n",
    "for v in vals:\n",
    "    if v < first_thresh:\n",
    "        CumOilCategory.append(category[0])\n",
    "    elif first_thresh <= v < second_thresh:\n",
    "        CumOilCategory.append(category[1])\n",
    "    else:\n",
    "        CumOilCategory.append(category[2])\n",
    "df[\"CumOilCategory\"] = CumOilCategory\n",
    "Counter(df[\"CumOilCategory\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=[\"CumOil12Month\", \"rowID    \", \"TotalWellCost_USDMM\",\n",
    " \"CompletionDate\", \"SurfaceHoleLongitude\", \"SurfaceHoleLatitude\", \"BottomHoleLongitude\", \"BottomHoleLatitude\"], inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "nominal_columns = ['Operator', 'Reservoir']\n",
    "other_columns =  ['LateralLength_FT', 'ProppantIntensity_LBSPerFT', 'FluidIntensity_BBLPerFT', \n",
    "'HzDistanceToNearestOffsetAtDrill', 'HzDistanceToNearestOffsetCurrent', 'VtDistanceToNearestOffsetCurrent', \n",
    "'VtDistanceToNearestOffsetAtDrill', 'WellDepth', 'ReservoirThickness', 'OilInPlace', 'Porosity', \n",
    "'ReservoirPressure', 'WaterSaturation', 'StructureDerivative', 'TotalOrganicCarbon', 'ClayVolume', 'CarbonateVolume', 'Maturity']\n",
    "#print(other_columns)\n",
    "for col in other_columns:\n",
    "    if col in df.columns:\n",
    "        df[col] = df[col].fillna(df[col].median())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc = OneHotEncoder(sparse_output=False, handle_unknown=\"ignore\")\n",
    "k = enc.fit_transform(df[[\"Operator\", \"Reservoir\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "onehot_df = pd.DataFrame(k, columns=enc.get_feature_names_out(), index=df.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_encoded = pd.concat([df.drop(columns=nominal_columns), onehot_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "df_encoded[other_columns] = scaler.fit_transform(df[other_columns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df_encoded[\"CumOilCategory\"]\n",
    "X = df_encoded.drop(columns=[\"CumOilCategory\"])\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train[\"CumOilCategory\"] = y_train\n",
    "X_test[\"CumOilCategory\"] = y_test\n",
    "\n",
    "X_train.to_csv(\"training/train.csv\", header=True, index=False, sep=\",\")\n",
    "X_test.to_csv(\"training/test.csv\", header=True, index=False, sep=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "#code_run = code.split(\"```python\")[1].split(\"```\")[0]\n",
    "code_run = \"\"\"import os\n",
    "import sys\n",
    "import pickle\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_predict, cross_val_score, GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "\n",
    "# Load train and test data from command line arguments\n",
    "train_data = pd.read_csv(sys.argv[1])\n",
    "test_data = pd.read_csv(sys.argv[2])\n",
    "\n",
    "# Extract features and labels\n",
    "X_train = train_data.drop('CumOilCategory', axis=1)\n",
    "y_train = train_data['CumOilCategory']\n",
    "X_test = test_data.drop('CumOilCategory', axis=1)\n",
    "y_test = test_data['CumOilCategory']\n",
    "\n",
    "# Train Random Forest Classifier\n",
    "print(\"Training Random Forest Classifier...\")\n",
    "rf = RandomForestClassifier()\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'max_depth': [None, 10, 20],\n",
    "    'min_samples_split': [2, 5, 10]\n",
    "}\n",
    "grid_search = GridSearchCV(rf, param_grid, cv=5)\n",
    "grid_search.fit(X_train, y_train)\n",
    "best_rf = grid_search.best_estimator_\n",
    "\n",
    "# Predict test data using the trained model\n",
    "print(\"Predicting test data...\")\n",
    "y_pred = cross_val_predict(best_rf, X_test, y_test, cv=5)\n",
    "\n",
    "# Calculate classification report\n",
    "print(\"Calculating classification report...\")\n",
    "classification_rep = classification_report(y_test, y_pred, output_dict=True)\n",
    "classification_df = pd.DataFrame(classification_rep).transpose()\n",
    "\n",
    "# Calculate feature importances\n",
    "print(\"Calculating feature importances...\")\n",
    "best_rf.fit(X_train, y_train)\n",
    "feature_importances = best_rf.feature_importances_\n",
    "feature_names = X_train.columns\n",
    "feature_importance_df = pd.DataFrame({'Feature': feature_names, 'Importance': feature_importances})\n",
    "\n",
    "# Select features with importance greater than 0\n",
    "selected_features = feature_importance_df[feature_importance_df['Importance'] > 0]['Feature']\n",
    "\n",
    "# Print precision, recall, and F1 score\n",
    "precision = classification_df.loc['weighted avg', 'precision']\n",
    "recall = classification_df.loc['weighted avg', 'recall']\n",
    "f1_score = classification_df.loc['weighted avg', 'f1-score']\n",
    "print(f\"Precision: {precision}, Recall: {recall}, F1 Score: {f1_score}\")\n",
    "\n",
    "# Save results as a dictionary\n",
    "results_dict = {\n",
    "    'classification_report': classification_df,\n",
    "    'feature_importances': feature_importance_df,\n",
    "    'selected_features': selected_features\n",
    "}\n",
    "\n",
    "# Save results dictionary as a pickle file\n",
    "with open('results_dict.pkl', 'wb') as f:\n",
    "    pickle.dump(results_dict, f)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = f\"generated_code.py\"\n",
    "with open(file_path, 'w') as file:\n",
    "    file.write(code_run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Random Forest Classifier...\n",
      "Predicting test data...\n",
      "Calculating classification report...\n",
      "Calculating feature importances...\n",
      "Precision: 0.6244461879176436, Recall: 0.6196078431372549, F1 Score: 0.6216378633621631\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Script completed successfully'"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def run_script_sys_executable(script_path, train_path, test_path):\n",
    "    # try:\n",
    "    #     result = subprocess.run(\n",
    "    #         [sys.executable, script_path] + list(args),\n",
    "    #         capture_output=True,\n",
    "    #         text=True,\n",
    "    #         check=True\n",
    "    #     )\n",
    "    #     return result.stdout\n",
    "    # except subprocess.CalledProcessError as e:\n",
    "    #     print(f\"An error occurred: {e}\")\n",
    "    #     print(f\"Error output: {e.stderr}\")\n",
    "    #     return None\n",
    "\n",
    "    try:\n",
    "            # Run the script with the paths to the temporary files\n",
    "        process = subprocess.Popen(\n",
    "            [sys.executable, script_path, train_path, test_path],\n",
    "            stdout=subprocess.PIPE,\n",
    "            stderr=subprocess.PIPE,\n",
    "            text=True,\n",
    "            bufsize=1,\n",
    "            universal_newlines=True\n",
    "        )\n",
    "        \n",
    "        # Stream output in real-time\n",
    "        for line in process.stdout:\n",
    "            print(line, end='')  # Print each line as it's generated\n",
    "        \n",
    "        # Wait for the process to complete and get the return code\n",
    "        return_code = process.wait()\n",
    "        \n",
    "        # If there was an error, print the error output\n",
    "        if return_code != 0:\n",
    "            print(\"Error occurred. Error output:\")\n",
    "            for line in process.stderr:\n",
    "                print(line, end='')\n",
    "            return None\n",
    "            \n",
    "        return \"Script completed successfully\"\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "run_script_sys_executable(file_path, \"training/train.csv\", \"training/test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"classification_metrics.pkl\", \"rb\") as f:\n",
    "    res_dict = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['svm_classification_report', 'rf_classification_report', 'svm_cross_val_scores', 'rf_cross_val_scores'])"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rf = res_dict[\"rf_classification_report\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_read = pd.read_csv(\"/Users/advaitbalaji/se_exercise/AnalysisData.csv\", header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SurfaceHoleLongitude</th>\n",
       "      <th>SurfaceHoleLatitude</th>\n",
       "      <th>BottomHoleLongitude</th>\n",
       "      <th>BottomHoleLatitude</th>\n",
       "      <th>Operator</th>\n",
       "      <th>CompletionDate</th>\n",
       "      <th>Reservoir</th>\n",
       "      <th>LateralLength_FT</th>\n",
       "      <th>ProppantIntensity_LBSPerFT</th>\n",
       "      <th>FluidIntensity_BBLPerFT</th>\n",
       "      <th>...</th>\n",
       "      <th>ReservoirPressure</th>\n",
       "      <th>WaterSaturation</th>\n",
       "      <th>StructureDerivative</th>\n",
       "      <th>TotalOrganicCarbon</th>\n",
       "      <th>ClayVolume</th>\n",
       "      <th>CarbonateVolume</th>\n",
       "      <th>Maturity</th>\n",
       "      <th>TotalWellCost_USDMM</th>\n",
       "      <th>CumOil12Month</th>\n",
       "      <th>rowID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-101.594663</td>\n",
       "      <td>32.305870</td>\n",
       "      <td>-101.602091</td>\n",
       "      <td>32.335669</td>\n",
       "      <td>FANG</td>\n",
       "      <td>11/6/2015</td>\n",
       "      <td>SPRABERRY LOWER SHALE</td>\n",
       "      <td>9897.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1805.9655</td>\n",
       "      <td>0.598</td>\n",
       "      <td>0.013</td>\n",
       "      <td>1.9589</td>\n",
       "      <td>0.214</td>\n",
       "      <td>0.284</td>\n",
       "      <td>0.853</td>\n",
       "      <td>4.8647</td>\n",
       "      <td>114929.0000</td>\n",
       "      <td>1001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-101.685000</td>\n",
       "      <td>32.285148</td>\n",
       "      <td>-101.694277</td>\n",
       "      <td>32.314904</td>\n",
       "      <td>PXD</td>\n",
       "      <td>7/24/2015</td>\n",
       "      <td>WOLFCAMP A</td>\n",
       "      <td>4563.0</td>\n",
       "      <td>1700.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3724.2295</td>\n",
       "      <td>0.320</td>\n",
       "      <td>0.013</td>\n",
       "      <td>2.2846</td>\n",
       "      <td>0.165</td>\n",
       "      <td>0.369</td>\n",
       "      <td>0.931</td>\n",
       "      <td>3.4619</td>\n",
       "      <td>62404.5195</td>\n",
       "      <td>1002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-101.619541</td>\n",
       "      <td>32.353532</td>\n",
       "      <td>-101.611362</td>\n",
       "      <td>32.333854</td>\n",
       "      <td>PXD</td>\n",
       "      <td>11/19/2015</td>\n",
       "      <td>WOLFCAMP B</td>\n",
       "      <td>4833.0</td>\n",
       "      <td>1508.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4153.2573</td>\n",
       "      <td>0.445</td>\n",
       "      <td>0.013</td>\n",
       "      <td>2.8439</td>\n",
       "      <td>0.170</td>\n",
       "      <td>0.283</td>\n",
       "      <td>0.930</td>\n",
       "      <td>3.5627</td>\n",
       "      <td>124884.8672</td>\n",
       "      <td>1003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-101.580465</td>\n",
       "      <td>32.326561</td>\n",
       "      <td>-101.588574</td>\n",
       "      <td>32.354169</td>\n",
       "      <td>OVV</td>\n",
       "      <td>5/9/2017</td>\n",
       "      <td>WOLFCAMP A</td>\n",
       "      <td>4799.0</td>\n",
       "      <td>2577.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3143.4885</td>\n",
       "      <td>0.327</td>\n",
       "      <td>0.002</td>\n",
       "      <td>2.7256</td>\n",
       "      <td>0.196</td>\n",
       "      <td>0.244</td>\n",
       "      <td>0.932</td>\n",
       "      <td>3.5130</td>\n",
       "      <td>98523.5625</td>\n",
       "      <td>1004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-101.424883</td>\n",
       "      <td>32.196781</td>\n",
       "      <td>-101.435495</td>\n",
       "      <td>32.237272</td>\n",
       "      <td>OVV</td>\n",
       "      <td>5/12/2017</td>\n",
       "      <td>WOLFCAMP A</td>\n",
       "      <td>5058.0</td>\n",
       "      <td>2467.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3817.9592</td>\n",
       "      <td>0.360</td>\n",
       "      <td>0.002</td>\n",
       "      <td>2.1426</td>\n",
       "      <td>0.137</td>\n",
       "      <td>0.416</td>\n",
       "      <td>0.932</td>\n",
       "      <td>3.6086</td>\n",
       "      <td>72951.4063</td>\n",
       "      <td>1005</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   SurfaceHoleLongitude  SurfaceHoleLatitude  BottomHoleLongitude  \\\n",
       "0           -101.594663            32.305870          -101.602091   \n",
       "1           -101.685000            32.285148          -101.694277   \n",
       "2           -101.619541            32.353532          -101.611362   \n",
       "3           -101.580465            32.326561          -101.588574   \n",
       "4           -101.424883            32.196781          -101.435495   \n",
       "\n",
       "   BottomHoleLatitude Operator CompletionDate              Reservoir  \\\n",
       "0           32.335669     FANG      11/6/2015  SPRABERRY LOWER SHALE   \n",
       "1           32.314904      PXD      7/24/2015             WOLFCAMP A   \n",
       "2           32.333854      PXD     11/19/2015             WOLFCAMP B   \n",
       "3           32.354169      OVV       5/9/2017             WOLFCAMP A   \n",
       "4           32.237272      OVV      5/12/2017             WOLFCAMP A   \n",
       "\n",
       "   LateralLength_FT  ProppantIntensity_LBSPerFT  FluidIntensity_BBLPerFT  ...  \\\n",
       "0            9897.0                         NaN                      NaN  ...   \n",
       "1            4563.0                      1700.0                     34.0  ...   \n",
       "2            4833.0                      1508.0                     37.0  ...   \n",
       "3            4799.0                      2577.0                     51.0  ...   \n",
       "4            5058.0                      2467.0                     52.0  ...   \n",
       "\n",
       "   ReservoirPressure  WaterSaturation  StructureDerivative  \\\n",
       "0          1805.9655            0.598                0.013   \n",
       "1          3724.2295            0.320                0.013   \n",
       "2          4153.2573            0.445                0.013   \n",
       "3          3143.4885            0.327                0.002   \n",
       "4          3817.9592            0.360                0.002   \n",
       "\n",
       "   TotalOrganicCarbon  ClayVolume  CarbonateVolume  Maturity  \\\n",
       "0              1.9589       0.214            0.284     0.853   \n",
       "1              2.2846       0.165            0.369     0.931   \n",
       "2              2.8439       0.170            0.283     0.930   \n",
       "3              2.7256       0.196            0.244     0.932   \n",
       "4              2.1426       0.137            0.416     0.932   \n",
       "\n",
       "   TotalWellCost_USDMM  CumOil12Month  rowID      \n",
       "0               4.8647    114929.0000       1001  \n",
       "1               3.4619     62404.5195       1002  \n",
       "2               3.5627    124884.8672       1003  \n",
       "3               3.5130     98523.5625       1004  \n",
       "4               3.6086     72951.4063       1005  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_read.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/se_exercise/.venv/lib/python3.10/site-packages/pandas/core/indexes/base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3804\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3805\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3806\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32mindex.pyx:167\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mindex.pyx:196\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7081\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7089\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 0",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[103], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mdf_read\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\n",
      "File \u001b[0;32m~/se_exercise/.venv/lib/python3.10/site-packages/pandas/core/frame.py:4102\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   4101\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 4102\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   4104\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[0;32m~/se_exercise/.venv/lib/python3.10/site-packages/pandas/core/indexes/base.py:3812\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3807\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[1;32m   3808\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[1;32m   3809\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[1;32m   3810\u001b[0m     ):\n\u001b[1;32m   3811\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[0;32m-> 3812\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   3813\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   3814\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3815\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3816\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3817\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 0"
     ]
    }
   ],
   "source": [
    "df_read[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>macro avg</th>\n",
       "      <th>weighted avg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.723898</td>\n",
       "      <td>0.538636</td>\n",
       "      <td>0.752475</td>\n",
       "      <td>0.66902</td>\n",
       "      <td>0.671670</td>\n",
       "      <td>0.671670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0.734118</td>\n",
       "      <td>0.557647</td>\n",
       "      <td>0.715294</td>\n",
       "      <td>0.66902</td>\n",
       "      <td>0.669020</td>\n",
       "      <td>0.669020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1-score</th>\n",
       "      <td>0.728972</td>\n",
       "      <td>0.547977</td>\n",
       "      <td>0.733414</td>\n",
       "      <td>0.66902</td>\n",
       "      <td>0.670121</td>\n",
       "      <td>0.670121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>support</th>\n",
       "      <td>425.000000</td>\n",
       "      <td>425.000000</td>\n",
       "      <td>425.000000</td>\n",
       "      <td>0.66902</td>\n",
       "      <td>1275.000000</td>\n",
       "      <td>1275.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    0           1           2  accuracy    macro avg  \\\n",
       "precision    0.723898    0.538636    0.752475   0.66902     0.671670   \n",
       "recall       0.734118    0.557647    0.715294   0.66902     0.669020   \n",
       "f1-score     0.728972    0.547977    0.733414   0.66902     0.670121   \n",
       "support    425.000000  425.000000  425.000000   0.66902  1275.000000   \n",
       "\n",
       "           weighted avg  \n",
       "precision      0.671670  \n",
       "recall         0.669020  \n",
       "f1-score       0.670121  \n",
       "support     1275.000000  "
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_rf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename columns 0, 1, 2 to low, medium, high\n",
    "df_rf = df_rf.rename(columns={\"0\": 'low', \"1\": 'medium', \"2\": 'high'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>low</th>\n",
       "      <th>medium</th>\n",
       "      <th>high</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>macro avg</th>\n",
       "      <th>weighted avg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.723898</td>\n",
       "      <td>0.538636</td>\n",
       "      <td>0.752475</td>\n",
       "      <td>0.66902</td>\n",
       "      <td>0.671670</td>\n",
       "      <td>0.671670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0.734118</td>\n",
       "      <td>0.557647</td>\n",
       "      <td>0.715294</td>\n",
       "      <td>0.66902</td>\n",
       "      <td>0.669020</td>\n",
       "      <td>0.669020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1-score</th>\n",
       "      <td>0.728972</td>\n",
       "      <td>0.547977</td>\n",
       "      <td>0.733414</td>\n",
       "      <td>0.66902</td>\n",
       "      <td>0.670121</td>\n",
       "      <td>0.670121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>support</th>\n",
       "      <td>425.000000</td>\n",
       "      <td>425.000000</td>\n",
       "      <td>425.000000</td>\n",
       "      <td>0.66902</td>\n",
       "      <td>1275.000000</td>\n",
       "      <td>1275.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  low      medium        high  accuracy    macro avg  \\\n",
       "precision    0.723898    0.538636    0.752475   0.66902     0.671670   \n",
       "recall       0.734118    0.557647    0.715294   0.66902     0.669020   \n",
       "f1-score     0.728972    0.547977    0.733414   0.66902     0.670121   \n",
       "support    425.000000  425.000000  425.000000   0.66902  1275.000000   \n",
       "\n",
       "           weighted avg  \n",
       "precision      0.671670  \n",
       "recall         0.669020  \n",
       "f1-score       0.670121  \n",
       "support     1275.000000  "
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_rf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdict = {\"rf_res\": df_rf}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"rf.pkl\", \"wb\") as f:\n",
    "    pickle.dump(rdict, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
